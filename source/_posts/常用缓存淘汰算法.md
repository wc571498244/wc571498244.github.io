---
title: 缓存淘汰算法：LRU、TTL
top: false
cover: false
toc: true
mathjax: true
date: 2021-06-14 19:19:30
password:
summary:
tags: Python
categories: 算法
---

### LRU Cache

LRU(Least recently used, 最近最少使用)，其核心思想是：如果一个数据最近一段时间被访问过，那么以后被访问的几率越高，如果一个数据最近一段时间没有被访问过，那么将来被访问的几率越小；当内存超过限制时，应当把最久没有访问的数据淘汰。

> 实现LRU

1. 用一个先进先出的队列来记录缓存的key，每当某个key被访问，就将该key入队；如果该key在这个队列里面，则将该key移至队尾；若队列已满，则淘汰队首的key。

2. 利用dict来存储key对应的数据项；当有新key入队，则该dict需要插入新数据项；若队列已满，同时要将队首的key所存储的数据项淘汰

代码：
```python

class LRUCache(object):
    def __init__(self, max_size):
        self.cache = {}
        self.keys = []
        self.max_size = max_size

    def visit_key(self, key):
        if key in self.keys:
            self.keys.remove(key)
        self.keys.append(key)

    def full(self):
        key = self.keys[0]
        self.keys = self.keys[1:]
        del self.cache[key]

    def get(self, key):
        if key not in self.keys:
            return -1
        value = self.cache[key]
        self.visit_key(key)
        return value

    def put(self, key, value):
        if key not in self.keys:
            if len(self.keys) == self.max_size:
                self.full()
        self.visit_key(key)
        self.cache[key] = value


```

### TTL Cache

TTL 简单来讲就是对数据缓存一定的时间
上代码：
```python
def ttl_cache(ttl):

    def wrapper(func):
        cache = {}
        
        def inner(*args, **kwargs):
            target = object()
            if kwargs:
                key = args + (repr(sorted(kwargs.items())), )
            else:
                key = args
            
            result = cache.get(key, target)
            if result is not target:
                exp, value = result
                if exp > time.time():
                    print("hit cache: {}".format(expire_at))
                    return value
            value = func(*args, **kwargs)
            print("miss cache")
            cache[key] = (time.time() + ttl, value)
            return value
            
        return inner
        
    return wrapper

```
